%!TEX root = Thesis_main.tex

\chapter{Controller}
\label{chapter5}

\section{Introduction and Aim of the controller}

In this chapter the core of the developed controller will be presented. The goal of our research is to solve the mobile manipulation problem of trajectory tracking for handling and grasping tasks. The tasks we wish to perform are in general solved decoupling the controller in order to move the mobile robot in a defined position in order to have a fixed position of the base during grasping and to reduce uncertainties in end-effector position, and only then perform the grasping task with the manipulator. This approach is generally reliable since controlling independently the base of the robot and the arm with well-known techniques allows precision and robustness. Anyway, if we want to perform the tasks in a time-optimal way this approach is not suitable. The possibility to move within an environment during grasping operation to allow faster performance time is a goal desired not only in manipulation tasks but for many applications. Furthermore, the usage of a unique controller could allow exploiting the many degrees of redundancy to optimize other process variables such as manipulability or obstacle avoidance capability. What we have developed, is a unique controller able to deal with the whole mobile manipulator system. The controller we developed aims at solving some of the issues presented in Chapter \ref{chapter4} by means of a Nonlinear Model Predictive Control with a novel approach to solve the online optimization problem reducing the overall computational time. The choice of MPC controller has been made for many reasons: 

\begin{itemize}
\item by means of predicting the future states through the definition of a model it is possible to forecast the behaviour of the system. This approach becomes useful for obstacle avoidance and in manipulability maximization tasks;
\item it is an open framework that allows customized problems;
\item introducing constraints allows taking into account the feasibility set of the joint variable as well as control input limits;
\item being an Optimal controller allows the minimization of customized costs such as manipulability, control input effort etc...
\item it is generally used as a high-level controller, the low-level loops are in charge to track given high-level commands and deal with system dynamic;
\end{itemize}

In the next section the general NMPC structure for the mobile manipulation problem will be explained referring to a nonholonomic vehicle and a 6 DOFs manipulator. Our novel approach to reduce computational time and a related stability analysis will be discussed later on.

\section{Problem Definition}

In this section the variables of the system and the model used for the MPC problem will be defined. The choice of the kinematic model instead of the dynamic one has been made for different reasons:

\begin{itemize}
\item even if our approach allows to reduce computational time, the usage of the dynamic model introduces further complexity to forecast the future states, this slow down significantly the solving time;
\item because the control action of the kinematic model has been defined as velocities, it is easy to implement velocity constraints;
\item low-level motor controllers are usually in charge to track velocities with higher frequency loops, this hierarchical approach is widely diffuse in controlling complex robotic systems;
\item from a user point of view, kinematic variables allows a better understanding of what is happening on the real system;
\end{itemize}

\subsection{Model}

Consider the kinematic relation in Equation \eqref{dirkinMM} and the new state variables defined as:
\begin{equation} \label{state_control_def}
{x}(t) \in \mathbb{R}^n\ \  \textnormal{s.t.}\ \  {x}  = \left[ \begin{matrix} x_b \\ y_b \\ \theta_b \\ \Theta_1 \\ \Theta_2 \\ \Theta_3 \\ \Theta_4 \\ \Theta_5 \\ \Theta_6 \end{matrix} \right]\ \   \textnormal{and}\ \  {u}(t) \in \mathbb{R}^m\ \ \textnormal{s.t.}\ \ {u}=\left[ \begin{matrix} v \\ \omega \\ \dot{\Theta}_1 \\ \dot{\Theta}_2 \\ \dot{\Theta}_3 \\ \dot{\Theta}_4 \\ \dot{\Theta}_5 \\ \dot{\Theta}_6 \end{matrix} \right]
\end{equation}
where $x_b,\ y_b,\ \theta_b$ are the mobile base coordinates, $\Theta_1, \cdots ,\Theta_6$ are the joint values of the manipulator arm, $v, \ \omega$ are the base longitudinal and angular velocities, and $\dot{\Theta}_1, \cdots ,\dot{\Theta}_6$ are the manipulator joint velocities.
By means of these variables the nonlinear kinematic model of the nonholonomic Mobile Manipulator can be defined as:
\begin{equation} \label{system_base}
	\dot{{x}}=f({x},{u})
\end{equation} 
where:
\begin{equation} \label{NLsystem}
	f({x},{u}) = \left[ \begin{matrix}
	G({x}) & 0 \\ 0 & I \end{matrix} \right]u
\end{equation}
and $G(x)$ is defined as in Equation \eqref{Gmatrix_def}:
\begin{equation*}
G({x}) =  \left[
\begin{matrix}
\cos\theta_b & 0 \\
\sin\theta_b & 0 \\
0 & 1 
\end{matrix}
\right] 
\end{equation*}

The continuous time model in \eqref{system_base} has been discretized by means of Runge Kutta 4 method, that results in:
\begin{equation} \label{system_base_d}
	{x}_{k+1}=f^+(x_k,u_k)
\end{equation}
Runge-Kutta method will be discussed more in detail later on.

\subsubsection*{Notation:}
We will use the same notation as in Chapter \ref{chapter3}. Briefly recalling: ${x}_{k|i}$ is the state vector at time instant $i$ propagated starting from time instant $k$, and ${u}_{k|i}$ is defined in the same way. Moreover $f^+$ will define the discrete Runge-Kutta function approximating $f$.

\subsection{NLP definition}

As done in Chapter \ref{chapter3} we will set up a minimization problem considering a quadratic cost function in the form:
\begin{equation}\label{J_continua}
J({x}_{k|0},\textbf{u}_{k|i})=\sum_{i=1}^{N}l({x}_{k|i},{u}_{k|i})
\end{equation} 
where $l({x}_{k|i},{u}_{k|i})$ is a positive definite function dependent on the state and the control action. By including Equation \eqref{system_base_d} and state and control feasibility boundaries the problem becomes: 
\begin{equation} \label{ourproblem_basic}
\begin{split}
		& min_{\textbf{u}_k}\ J({x}_{k|0},\textbf{u}_{k}) \\
		\textnormal{s.t.}\qquad
		&\ \ \ \ x_{k|i+1}=f^+(x_{k|i},u_{k|i}) \\
		&\ \ \ \ {x}_{k|i} \in \mathbb{X}\ \forall i=1,\dots,\ N  \\
		&\ \ \ \ {u}_{k|i} \in \mathbb{U}\ \forall i=0,\dots,\ N-1 \\
	\end{split}	
\end{equation}
where $\mathbb{X} = \lbrace {x}\in \mathbb{R}^n\ \textnormal{s.t.}\ {x}_{min}\leq x_k\leq x_{max} \rbrace$ is the feasible region of the state, $\mathbb{U} = \lbrace {u}\in \mathbb{R}^m\ \textnormal{s.t.}\ {u}_{min}\leq{u}\leq{u}_{max}, f^+(x_k,u_k) \in \mathbb{X} \rbrace $ and $\textbf{u}_k=[\ u_{k|0},\ u_{k|1},\ \dots,\ u_{k|N-1}\ ]$.
Note that the problem is discrete; we will refer at $T$ as the discretization time, so the time between $k$ and $k+1$ as well as the time between $i$ and $i+1$. \\
The problem defined in \eqref{ourproblem_basic} is a standard NMPC problem that can be solved using well-known numerical optimization methods. The solution to the problem so defined will be $\textbf{u}^* \in \mathbb{R}^{m\times N}\ \textnormal{s.t.}\ \textbf{u}^* =[{u}^*_{k|0},\ {u}^*_{k|1},\ \dots,\ {u}^*_{k|N-1}]$. Even if, according to receding horizon logic, only the first computed control action ${u}^*_{k|0}$ will be applied, the problem needs to be solved for all the prediction horizon. Because of that, the dimension of the problem is highly dependent on N. Considering our case, for example, we have $m=8$, so if we set $N=20$ the dimension of $\textbf{u}^*$ that has to be found is $8\times20=160$. The dependence of the problem dimension on the optimization horizon length generate restrictions on the choice of $N$. This is due to the increase in computational effort that may become too high to solve fast online applications like handling and grasping for mobile manipulators. A solution could be to bound the value of $N$ in order to keep the problem within a solvable dimension. However, the performance clearly increases as $N$ increases, allowing compliance with some constraints, like obstacle avoidance, over a longer period. For this reason, we introduced a parameterized control input approach to reduce the dependence of $N$ on the solving time, without losing the advantages of a longer prediction horizon.

\subsection{Parameterization}
The problem in \eqref{ourproblem_basic} uses a control action defined as piece-wise constant that, as explained before, brings high computational cost dependence on $N$. To solve this issue we propose to express the control vector as a function of some parameters.
Let's consider a continuous time parametrization for the control input $u$ defined as:
\begin{equation}
{u}(t)=F(t)p
\label{param_eq_cont}
\end{equation}
where $p \in \mathbb{R}^{N_p}$ s.t. $p=[\ p_1,\ p_2,\ \dots,\ p_{N_p}\ ]^T$. Considering this parameterization, the state equation of the system becomes:
\begin{equation}
	f(x,F(t)p)=\tilde{f}(x,p,t)
	\label{state_eq_par}
\end{equation}
Because the problem we aim to solve is defined as a discrete time problem, we will redefine Equation \eqref{param_eq_cont} as discrete:
\begin{equation}\label{param_eq}
{u}_{k|i}=F(t_i)p_k
\end{equation}
where $t_i=(i-1)T\ \forall i=1,\ \dots,\  N$, and the matrix $F(t_i)$ is the base of the new space $\mathbb{R}^{N_p}$. The subscript $k$ for $p$ indicates the time instant the parameterization is referred to. \\
A good choice of the parameterization is made according to the physics of the variables to be parameterized. In \cite{kelly2013mobile} a parametric optimal approach is proposed, anyway, given that the variables to be controlled are longitudinal and angular velocities, a polynomial parameterization can fit the physical meaning requirement. \\
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.4]{param_horizon}
	\caption{Control input parameterization}
	\label{param_horizon}
\end{figure}
Considering a 3rd order polynomial parameterization for the control inputs, as represented in Figure \ref{param_horizon}, each row of the ${u}$ vector can be expressed as a function of four parameters, for example $v=p_1t_i^3+p_2t_i^2+p_3t_i+p_4$. More in general ${u}_{k|i}$ is
\begin{equation}
{u}_{k|i}=\underbrace{\left[ \begin{matrix}
H_v(t_i)          & 0 & \dots      & 0  \\
0 &     H_\omega(t_i)      & \dots      & 0  \\
\vdots     & \vdots     & \ddots     & \vdots      \\
0 & \dots      & 0 &   H_{\Theta_6}(t_i)         \\
\end{matrix} \right]}_{F(t_i)} \left[ \begin{matrix} {p_v}_k \\ {p_{\omega}}_k \\ {p_{\Theta_1}}_k \\ {p_{\Theta_2}}_k \\ \vdots \\ {p_{\Theta_6}}_k \end{matrix} \right]
\end{equation}
where: 
\begin{equation}
\left[ \begin{matrix} {p_v}_k \\ {p_{\omega}}_k \\ {{p}_{\Theta_1}}_k \\ {{p}_{\Theta_2}}_k \\ \vdots \\ {{p}_{\Theta_6}}_k \end{matrix} \right] = \left[ \begin{matrix} {p_1}_k \\ {p_2}_k \\ {p_3}_k \\ \vdots \\ {p_{32}}_k \end{matrix} \right]\ \ \textnormal{and }\ \ H_*(t_i)=[\ t_i^3\ \ t_i^2\ \ t_i\ \ 1\ ]
\end{equation}
where $H_*(t_i)$ indicates each element on the diagonal of $F(t_i)$. Note that the value of $H_*(t_i)$ varies along the prediction horizon depending on the $i$th time instant. 

%%%%%%%%%%
Now, to discretize the continuous system in Equation \eqref{state_eq_par} we will use Runge-Kutta 4, so defining: 
\begin{equation*}
\begin{split}
    &k_1 = \tilde{f}(x_{k|i},p_k,t_i) \\
	&k_2 = \tilde{f}(x_{k|i}+k_1\frac{T}{2},p_k,t_i+\frac{T}{2}) \\
	&k_3 = \tilde{f}(x_{k|i}+k_2\frac{T}{2},p_k,t_i+\frac{T}{2})\\
	&k_4 = \tilde{f}(x_{k|i}+k_3T,p_k,t_i+\frac{T}{2})\\
\end{split}	
\end{equation*}
The new state equation becomes:  
\begin{equation}\label{state_eq_param}
\begin{split}
	x_{k|i+1}&=x_{k|i}+\frac{T}{6}(k_1+2k_2+2k_3+k4) \\
	&=\tilde{f}^+(x_{k|i},p_k,t_i)
\end{split}
\end{equation}
where $\tilde{f}^+$ denotes now the discretized parameterized state equation.
By applying the change of variables of Equation \eqref{param_eq} into the problem formulation in \eqref{ourproblem_basic} we obtain:
\begin{equation} \label{ourproblem_param}
\begin{split}
		& min_{p_k}\ J({x}_{k|0},p_k) = \sum_{i=1}^{N}\tilde{l}({x}_{k|i},p_k) \\
		\textnormal{s.t.}\qquad
		&\ \ \ \ x_{k|i+1}=\tilde{f}^+(x_{k|i},p_k,t_i) \\
		&\ \ \ \ {x}_{k|i} \in \mathbb{X}\quad \forall i=1,\dots, N  \\
		&\ \ \ \ p_k   \in \mathbb{P}\ \\
	\end{split}	
\end{equation}
where $\mathbb{P} = \lbrace p\in \mathbb{R}^{N_p}\ \textnormal{s.t.}\ F(t_i)p \in \mathbb{U}\quad \forall i = 1, \dots, N-1 \rbrace $ and $\tilde{l}$ is the stage cost $l$ as in Equation \eqref{J_continua} being expressed as a function of $p_k$ instead of ${u}_{k|i}$. By means of this substitution the problem has to be minimized with respect to $N_p$ parameters, whose number do not depend on $N$. As a matter of fact, using 3rd order polynomials as in the previous example, we have to minimize $J$ with respect to $32$ parameters for any length of the prediction horizon. Implementing this approach results in a faster solution of the optimization problem, and the possibility to enlarge significantly the prediction horizon. Anyway $N$ has to be chosen properly: increasing too much the prediction horizon may result in bad performances due to overconstraining of the control action. This effect, as well as a performance comparison with respect to traditional MPC will be discussed in the following chapters.
\subsection{Increasing-Weight Cost Function definition}

Once the problem has been defined in its general form we have to properly choose the cost function. In particular, the stage cost $\tilde{l}$ has to be defined. A common choice is to use a quadratic stage cost in order to have a positive definite cost function. Even if it is important to have a quadratic cost function for the stability of the controller, it is still possible to find suboptimal solutions (i.e. local minima) because of the nonlinearities of the system. We will define the stage cost $\tilde{l}$ as a sum of different contributions using increasing weights into the optimization horizon, 
\begin{equation}\label{costfunctionh}
J({x}_{k|0},p_k)=\sum_{i=1}^{N}\left(\frac{i}{N}\right)^b \left[ \sum_{j=1}^{5} h_j({x}_{k|i},p_k) \right]=\sum_{i=1}^{N}\left(\frac{i}{N}\right)^b h({x}_{k|i},p_k)
\end{equation} 
where $b\in\mathbb{N}$ is the exponent of the weight term. This approach allows, by means of increasing weighted stage costs, to assess the stability of the NMPC without the imposition of terminal constraints, as shown in \cite{alamir2018stability}.
The definition of the functions $h_j$ defines what we want to minimize. Because the aim of the controller is to track the trajectory of the end-effector solving the mobile manipulation problem, the following stage costs are defined:
\begin{itemize}

\item first of all, $h_1$ is the cost related to the end effector pose error defined as: 
\begin{equation}
\begin{split}
h_1 = \left[\begin{matrix} \xi_{k|i}-\xi_{{d}_{k|i}} \\ [1\ 1]^T-\Phi_{k|i} \end{matrix}\right]^T W_1\left[\begin{matrix} \xi_{k|i}-\xi_{{d}_{k|i}} \\ [1\ 1]^T-\Phi_{k|i}\end{matrix}\right]\textbf{}
\end{split}
\end{equation}
Defining:
\begin{equation} 
\xi_{k|i} = \left[ \begin{matrix} x_{{ee}_{k|i}} \\ y_{{ee}_{k|i}} \\ z_{{ee}_{k|i}} 
\end{matrix} \right] = \left[ \begin{matrix}
1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0
\end{matrix} \right]A_{{ee}_{k|i}}\left[ \begin{matrix}
0 \\ 0 \\ 0 \\ 1
\end{matrix} \right]
\end{equation} 
and
\begin{equation}
\Phi_{k|i}=\left[\begin{matrix}\vec{\vartheta}_{k|i}\cdot\vec{\vartheta}_{d_{k|i}}\\ \vec{\psi}_{k|i}\cdot\vec{\psi}_{d_{k|i}}
\end{matrix}\right] 
\end{equation}

where $A_{{ee}_{k|i}}$ is the rototranslation matrix of the end effector with respect to the global reference frame, which is a function of the state $x$;  $\vec{\vartheta}_{k|i}$ and $\vec{\psi}_{k|i}$ are the orientation vectors of the end effector (i.e. the first and the third columns of $A_{{ee}_{k|i}}$) and $W_1$ is the diagonal weighting matrix for cost $h_1$.

\item In order to maximize the manipulability a cost related to the manipulability of the system is defined as:
\begin{equation}
h_2 = W_2 \left( \frac{1}{\det({\mathcal{J}_{ee}}_{k|i}^T{\mathcal{J}_{ee}}_{k|i})} \right)^2
\end{equation}

where ${\mathcal{J}_{ee}}_{k|i}=[\ {\mathcal{J}_b(x)}_{k|i}\ {\mathcal{J}_a(x)}_{k|i}\ ]$ are the Jacobians which relates the end effector translational and rotational velocities to the joint speeds of the base and of the arm, respectively. Like before, $W_2$ is a weighting term. As briefly mentioned in Chapter \ref{chapter4}, there are many other ways to express an index for the manipulability of the system. For example, another way this index can be described is with the sine of the elbow joint angle of the manipulator, since the manipulability depends mostly on that angle.
    
\item $h_3$ is the cost related to the base control effort defined as: 
	\begin{equation}
	        h_3=\left[ \begin{matrix} v_{k|i-1} \\ \omega_{k|i-1} \end{matrix}\right]^T W_3 \left[ \begin{matrix} v_{k|i-1} \\ \omega_{k|i-1} \end{matrix}\right]
	 \end{equation}
This cost is particularly useful since the higher it is, the less the controller will choose to make adjustments on the end effector position through motions of the base, given that its positioning system is less reliable than the manipulator's one.
\item $h_4$ will be used to consider the base positioning error with respect to a given planned trajectory $x_{d_{base}}$ to reach the grasping area:
    \begin{equation}
        h_4=[x_{base}-x_{d_{base}}]^T W_4 [x_{base}-x_{d_{base}}]
    \end{equation}
 \item $h_5$ will be used to control the arm in joint space, so to track a desired joint position ${x_d}_{arm}$:
\begin{equation}
   h_5=[x_{arm}-{x_d}_{arm}]^T W_5 [x_{arm}-{x_d}_{arm}]
\end{equation}
where $x_{base}$ and $x_{arm}$ are defined as in Equation \eqref{dirkinMM}.
This terms, allowing to directly compute the error without passing through the forward kinematics, simplify a lot the problem during the motion of the base allowing a faster computation of the control action.
\end{itemize}
While a weighted composition of all the terms is used during grasping tasks, only $h_4$ and $h_5$ will be used moving the system towards and from the grasping area. Decoupling the problem with two different cost functions allows having a faster controller during the motion of the system when it is required to have high speeds, and to increase the complexity of the problem only when the system moves slower to perform the grasping task.\\
We have shown only few terms, but others can also be added to make the controller more completely defined or to make it choose a solution for the kinematic redundancy problem in a different way. 

\section{Stability}\label{stabproof}

Once the NMPC problem has been formulated and the feasibility of the problem has been analyzed as in Equation \eqref{feasibility} guaranteeing the fulfillment of hard  constraints, its stability has to be investigated. A proof of a terminal constraint-free approach for a nonlinear MPC is presented in \cite{alamir2018stability}. Anyway, parameterizing the control actions as in our approach, some considerations have to be done. \\
We will consider a zero-reference tracking problem considering the change of variables:
\begin{equation}\label{change_var}
    e_k=x_k-{x_d}_k
\end{equation}
and so, substituting \eqref{change_var} in the state equation \eqref{state_eq_param}, we can define:
\begin{equation}
	\tilde{f}^+(e_{k|i}-{x_d}_k,p_k,t_i)-{x_d}_{k|i+1}=\hat{f}^+(e_{k|i},p_k,{{x_d}_{k|i}},{{x_d}_{k|i+1}},t_i) 
\end{equation}
then the discrete error state equation becomes:
\begin{equation}\label{sys_eq_con_e}
    e_{k|i+1}=\hat{f}^+(e_{k|i},p_k,{{x_d}_{k|i}},{{x_d}_{k|i+1}},t_i)=\hat{f}^+(e_{k|i},p_k,t_i)
\end{equation}
Note that, for simplicity of notation, the system equation in \eqref{sys_eq_con_e} has been expressed as a function of the state error ${e_{k|i}}$ and the parameters $p_k$ only, given that the desired states are known.\\
In this way the problem is moved to track a zero error reference and becomes: 
\begin{equation} \label{ourproblem_stab}
\begin{split}
		& min_{{p}_k}\ J({e}_{k|0},{p}_k) =\sum_{i=1}^{N}\left(\frac{i}{N}\right)^b\hat{h}(e_{k|i},{p}_{k}) \\
		\textnormal{s.t.}\qquad
		&\ \ \ \ e_{k|i+1}=\hat{f}^+(e_{k|i},p_k,t_i) \\
		&\ \ \ \ e_{k|i} \in \mathbb{E}\ \forall i=1,\dots,\ N  \\
		&\ \ \ \ {p}_k\   \in \mathbb{P}\ \\
	\end{split}	
\end{equation}
where $\mathbb{E} = \lbrace {e}\in \mathbb{R}^n\ \textnormal{s.t.}\ {e}_{min}\leq e\leq e_{max} \rbrace$ is the feasible region of the state error and $\hat{h}$ is the stage cost function in \eqref{costfunctionh} considering the change of variables in Equation \eqref{change_var}. \\
Now, requiring that the point $e=0$ is a stable equilibrium point for the closed loop system means to establish that $J$ is a Lyapunov function, i.e. to assess that: 
\begin{equation}
	J({e}_{k+1|0},p^*_{k+1}) \leq J({e}_{k|0},p^*_k)
	\label{lyap_stab}
\end{equation}
Usually the most used approaches to verify this relies on a terminal constaint for the problem (i.e. $e_{k|N}=0$) or requiring the existence of a terminal set.
Anyway, the novelty of our approach lies in the absence of the terminal constraint and on the parameterization of the control action. Because of the latter, the extension of what done in \cite{alamir2018stability} is not straightforward and requires more general observations. \\
Given the optimal solution to the problem in \eqref{ourproblem_stab} at time instant $k$ defined as $p_k^*=\left[ p_{k_1}^*,\ p_{k_2}^*,  \dots,\ p_{k_{N_p}}^* \right]^T$ that corresponds to $  \textbf{u}_k^*=[\ u_{k|0}^*,\ u_{k|1}^*,\  \dots,\  u_{k|{N-1}}^*\ ]$, consider the parameterization $\tilde{p}_{k+1}$ such that the correspondent control input is $  \tilde{\textbf{u}}_{k+1}=[\ u_{k|1}^*,\ u_{k|2}^*,\  \dots,\  u_{k|{N-1}}^*,\ \bar{u}_{k|N} \ ]$, where $\bar{u}_{k|N}$ does not belong to the optimal solution at time step $k$ but it is described with the same parameters. A clear graphical rapresentation of this can be seen in Figure \ref{param_translatability}. This is possible if the parameterization chosen to describe the control variables is translatable, i.e. the relation $F(t_i)p_1=F(t_{i+1})p_2$ is always valid for some $p_1$ and $p_2$.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.35]{trans_u.jpg}
	\caption{Translatability of the $F$ function}
	\label{param_translatability}
\end{figure}
The cost function generated from $\tilde{p}_{k+1}$ will be then:
\begin{equation}
	J({e}_{k+1|0},\tilde{p}_{k+1})=\sum_{i=1}^{N}\left(\frac{i}{N}\right)^b\hat{h}(e_{k+1|i},\tilde{p}_{k+1})
\end{equation}
which, for the definition of $\tilde{p}_{k+1}$, can be rewritten as:
\begin{equation}
\begin{split}
	J({e}_{k+1|0},\tilde{p}_{k+1})=J({e}_{k|0},p^*_k) -\left( \frac{1}{N} \right)^b\hat{h}(e_{k|1},p^*_{k}) + \hat{h}(\hat{f}^+(e_{k|N},p^*_k,t_N),p^*_k) \\
\end{split}
\end{equation}
Rearranging the terms:
\begin{equation}
\begin{split}
	\underbrace{J({e}_{k+1|0},\tilde{p}_{k+1})-J({e}_{k|0},p^*_k)}_{D}= \hat{h}(\hat{f}^+(e_{k|N},p^*_k,t_N),p^*_k) -\left( \frac{1}{N} \right)^b\hat{h}(e_{k|1},p^*_{k}) \\
\end{split}
\end{equation}
Verifying that the term $D$ is less than or equal to zero, means to assess the stability of the system because, for the definition of optimality of the solution, that also implies: $J({e}_{k+1|0},p^*_{k+1}) - J({e}_{k|0},p^*_k) \leq 0$, i.e. the relation in \eqref{lyap_stab} holds. Therefore, $D\leq0$ admit a solution for any $k$, if 
\begin{equation}
\begin{split}
	\hat{h}(\hat{f}^+(e_{k|N},p^*_k,t_N))-\left( \frac{1}{N} \right)^b\hat{h}(e_{k|1},p^*_{k}) \leq 0 \\
\end{split}
\end{equation}
is always true for any $k$. Theoretically a value of $b$ for which the point $e=0$ is a stable equilibrium point for the closed loop system always exists, but it is not possible to define it precisely. This because it depends on the values of $\hat{h}(\cdot,\cdot)$; for example it is possible to have $\hat{h}(e_{k|1},p^*_{k})=0$ implying the need of $b=-\infty$ which is not practically possible.\\ The discussion is therefore reduced to the capacity of the solver decreasing the cost function with a parameterization $\tilde{p}_{k+1}$. This requirement, as shown in \cite{alamir_boh}, can be verified by looking at solving time and solver capabilities.


\section{Constraints}
Constraints will be introduced in order to properly define the problem taking into account feasibility configurations, maximum velocities and accelerations as well as to avoid self-collision of the system. Introducing constraints in the problem \eqref{ourproblem_param} does not affect the stability since limiting state and control is equal to redefine accordingly sets $\mathbb{P}$ and $\mathbb{E}$. 

In particular, the constraint definition has been divided into: 

\subsubsection*{Joint position constraints}
	To limit the configurations of the robot into feasible sets and to avoid the arm to self collide there are different approaches. We decided to limit the possible positions of the joints of the arm into feasible ranges. This means to generate a set:
	\begin{equation}
		\mathbb{X}_{arm}:=x_{arm} \in \mathbb{R}^{6}\ \ \text{s.t.}\ \  x_{arm,min}\ \leq\ x_{arm}\ \leq\ x_{arm,max} 
	\end{equation}
	Applying this constraint into the MPC problem defined in Equation \eqref{ourproblem_param} is straigthforward given that $\mathbb{X}_{arm}$ is a subset of $\mathbb{X}$.
\subsubsection*{Base position constraints}
	Contrary to the manipulator, self-collision of the base of the system is not possible and the joint $q_b$ could remain unconstrained. Anyway, the $x$ and $y$ coordinates of the base have been limited to define a region of operation for the Mobile Manipulator, see an example in Figure \ref{xy_limits}. This constraint is particularly useful performing experiments defining a map of the surrounding environment. As before: 
	\begin{equation}
		\mathbb{X}^{x_{base}}:=x_{base} \in \mathbb{R}^3\ \ s.t.\ \  x_{base,min}\ \leq\ x_{base}\ \leq\ x_{base,max} 
	\end{equation}

	\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.25]{IMMAGINI/xy_limits.png}
	\caption{Base $x-y$ limits}
	\label{xy_limits}
	\end{figure}

	Base and joint position constraints can be written in a compact form and for the entire prediction horizon redefining: 
	\begin{equation}
	\mathbb{X}:= x \in \mathbb{R}^{n}\ \ \text{s.t.}\ \  {x}_{min}\ \leq\ x\ \leq\ {x}_{max}
	\end{equation}

\subsubsection*{Velocity constraints}
	To take into account the maximum velcities allowed by the system, the control actions have been limited into minimum and maximum velocities according to manufacturer data in particular $\mathbb{R}^m$ have been redefined as:
	\begin{equation}
	\mathbb{U}:=\ {u}_{k|i} \in \mathbb{R}^m\ \ \textnormal{s.t.}\ \ u_{min}\leq{u_{k|i}}\leq u_{max}\ \ \forall i=0,\dots, N-1
	\label{vel_constr}
	\end{equation}
	According to the chosen parameterization, the constraint has to be defined in parametric form, i.e. we have to map $\mathbb{R}^m$ in $\mathbb{P}$. The constraint to be included in the problem in Equation \eqref{ourproblem_param} requires that:
	\begin{equation*}
		\mathbb{P}:=p_k \in \mathbb{R}^{N_p}\ \textnormal{ s.t. Eq.\eqref{vel_constr} is satisfied}
	\end{equation*}
\subsubsection*{Acceleration constraints}
	Given that any real system is not capable to perform infinite accelerations, a constraint to limit the computed velocity control input has to be defined. In particular, given that the controller compute control actions with a frequency $f_c=\frac{1}{T}$, the acceleration constraint is in the form:
	\begin{equation}
		\begin{split}
			\lvert u_{k|0}\rvert &\leq \lvert u_{k-1|0}\rvert + a_{max} T\qquad \textnormal{and}\\
			\lvert u_{k|i+1}\rvert &\leq \lvert u_{k|i}\rvert + a_{max} T\quad  \forall i=0,\dots,N-1
		\end{split}	
		\label{acc_constr}
	\end{equation}  

	where $a_{max}$ is the vector of the maximum allowable acceleration. As done for velocity constraints this has to be written as a constraint on parameters, and results in requiring also that:
	\begin{equation*}
		\mathbb{P}:=p_k \in \mathbb{R}^{N_p}\ \textnormal{ s.t. Eq.\eqref{acc_constr} is satisfied}
	\end{equation*}
\subsubsection*{Self collision avoidance}
	To avoid self collision of the system (i.e. the arm with the base), an approach similar to the one in \cite{sandberg1988collision} has been used. In particular spheres to encompass the base and the last joints have been defined as in Figure \ref{spheres_3d}.
	\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.4]{IMMAGINI/spheres_3d.png}
	\caption{Spheres for self collision avoidance}
	\label{spheres_3d}	
	\end{figure}
	Formally the self collision avoidance constraint has been defined requiring that: 
	\begin{equation}
	\begin{split} 
		&\sqrt{({C_0}_x-{C_1}_x)^2+({C_0}_y-{C_1}_y)^2+({C_0}_z-{C_1}_z)^2} + r_1 +r_0 \geq 0 \\
		&\ \ \ \ \textnormal{and} \\
		&\sqrt{({C_0}_x-{C_2}_x)^2+({C_0}_y-{C_2}_y)^2+({C_0}_z-{C_2}_z)^2} + r_2 +r_0 \geq 0 \\
	\end{split}
	\label{spheres_const}
	\end{equation}
	where ${C_0}_{x,y,z},{C_1}_{x,y,z} \text{and }{C_2}_{x,y,z}$ are the coordinates of the centres of the end effector and base spheres, respectively, defined in the reference frame of the base. $r_0$, $r_1$ and $r_2$ are the respective radii, defined according to the physical dimensions. This constraints definition introduces a nonlinear equation that has to be satiflied in the solution of \eqref{ourproblem_param}. \\

Summarizing, the presented constraints redefines the problem as:
\begin{equation} 
	\begin{split}
			& min_{p_k}\ J({x}_{k|0},p_k) = \sum_{i=1}^{N}\tilde{l}({x}_{k|i},p_k) \\
			\textnormal{s.t.}\qquad
			&\ \ \ \ x_{k|i+1}=\tilde{f}^+(x_{k|i},p_k,t_i) \\
			&\ \ \ \ {x}_{min}\ \leq\ x_{k|i}\ \leq\ {x}_{max}\  \forall\ i=1,\dots,\ N  \\
			&\ \ \ \ 0 \leq g^{sc}_{k|i}(x)\ \ \forall\ i=1,\dots,\ N \\
			&\ \ \ \ p_k\   \in \mathbb{P}\ \\
	\end{split}	
	\label{ourproblem_param_vinc}
\end{equation}
where $g^{sc}_{k|i}(x)$ is the function that defines the spheres constraints as in Equation \eqref{spheres_const}

